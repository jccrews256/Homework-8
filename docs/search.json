[
  {
    "objectID": "Homework 8.html",
    "href": "Homework 8.html",
    "title": "Homework 8",
    "section": "",
    "text": "Introduction\nThe goal of this work is to practice fitting linear models and evaluating the predictive ability of those models. For this practice, we will use bike share rental data from the Seoul bike share program. The goal will be to effectively predict daily bike share rentals.\n\n\nLoading Packages\nBefore getting started, we need to load in some packages.\n\n#Loading packages\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tune         2.0.1 \n✔ infer        1.0.9      ✔ workflows    1.3.0 \n✔ modeldata    1.5.1      ✔ workflowsets 1.1.1 \n✔ parsnip      1.3.3      ✔ yardstick    1.3.2 \n✔ recipes      1.3.1      \n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(broom)\nlibrary(knitr)\nlibrary(skimr)\nlibrary(kableExtra)\n\nWarning: package 'kableExtra' was built under R version 4.3.3\n\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(patchwork)\nlibrary(rsample)\n\n#Ensuring we don't print in scientific notation\noptions(scipen=999)\n\n\n\nReading in Data\nNow we will read in the Seoul bike share data. In the code chunk below, note that we must specify that the encoding is “latin1” in order to read in the data without error.\n\nbike_share_data&lt;-read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\",locale = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nExploratory Data Analysis\n\nChecking the Data\nBefore we model the data, we need to do some standard validation checks.\nFirst, we will check whether any of the variables have missing values.\n\n#Capturing number of missing values by variable\nbike_share_data |&gt;\n  summarize(across(everything(),~sum(is.na(.x))))\n\n# A tibble: 1 × 14\n   Date `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n  &lt;int&gt;               &lt;int&gt; &lt;int&gt;             &lt;int&gt;         &lt;int&gt;\n1     0                   0     0                 0             0\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;int&gt;, `Visibility (10m)` &lt;int&gt;,\n#   `Dew point temperature(°C)` &lt;int&gt;, `Solar Radiation (MJ/m2)` &lt;int&gt;,\n#   `Rainfall(mm)` &lt;int&gt;, `Snowfall (cm)` &lt;int&gt;, Seasons &lt;int&gt;, Holiday &lt;int&gt;,\n#   `Functioning Day` &lt;int&gt;\n\n\nImpressively, none of the variables have missing values. This is a great dataset!\nNext, we will confirm that the variable/column types set by read_csv are logical.\n\n#Checking variable types\nstr(bike_share_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nOutside of Date being a character instead of a date, and Seasons,Holiday, and Functioning Day being character types instead of factors, things look good! We can address those issues in a bit.\nA tricky variable is Hour, as it is “circular”; hour 23 of one day is only 60 minutes from hour 0 of the next day. We will go ahead and convert this to a factor to be safe.\n\n#Converting Hour to a factor variable\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(Hour = factor(Hour))\n\nAs additional validity checks, we will explore the values of each variable. To do so, we will generate basic summary statistics for the numeric variables and list the distinct values of the categorical variables.\n\n#Generating basic summary statistics for the numeric variables\nbike_share_data |&gt;\n  summarize(across(where(is.numeric),list(\"mean\" = mean,\n                                     \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(everything(),names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 9 × 7\n  variable                       mean  median      sd     IQR   min     max\n  &lt;chr&gt;                         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Rented Bike Count          705.      504.   645.     874.     0   3556   \n2 Temperature(°C)             12.9      13.7   11.9     19    -17.8   39.4 \n3 Humidity(%)                 58.2      57     20.4     32      0     98   \n4 Wind speed (m/s)             1.72      1.5    1.04     1.4    0      7.4 \n5 Visibility (10m)          1437.     1698    608.    1060     27   2000   \n6 Dew point temperature(°C)    4.07      5.1   13.1     19.5  -30.6   27.2 \n7 Solar Radiation (MJ/m2)      0.569     0.01   0.869    0.93   0      3.52\n8 Rainfall(mm)                 0.149     0      1.13     0      0     35   \n9 Snowfall (cm)                0.0751    0      0.437    0      0      8.8 \n\n\nLooking at the summary statistics for the numeric variables, nothing seems particularly concerning. However, I admit that I am not very knowledgeable of the normal range for solar radiation.\nFor the categorical variables, we won’t worry about Date; we will check the range of this variable once we convert is to a date type.\n\n#Listing unique values of the categorical and factor variables excluding Date\nbike_share_data |&gt;\n  select(Hour, Seasons, Holiday, `Functioning Day`) |&gt;\n  map(unique)\n\n$Hour\n [1] 0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 23\nLevels: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nNo concerning values here.\nOnto Date. We need to make this a date type so that it is more easily used. We can use the lubridate package for that.\nAfter making the conversion, we can confirm the conversion worked by looking at the structure and extracting the min and max dates.\n\n#Converting Date to a date\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(Date = dmy(Date))\n\n#Confirming change\nstr(bike_share_data$Date)\n\n Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" ...\n\n#Extracting min and max\nbike_share_data |&gt;\n  summarize(min = min(Date),max = max(Date))\n\n# A tibble: 1 × 2\n  min        max       \n  &lt;date&gt;     &lt;date&gt;    \n1 2017-12-01 2018-11-30\n\n\nLooking at the structure as well as the endpoints of the date range, everything looks good! It seems we have a year of data starting on December 12, 2017, and ending on November 30, 2018.\nLet’s convert the remaining character types to factors. Given the current values are generally informative, we won’t worry about creating any new labels for the levels.\n\n#Converting character types to factors\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(across(where(is.character),factor))\n\nBefore we move on to exploring our data more deeply, let’s convert the names to ones that are more R-friendly and consistent.\n\n#Converting to more friendly variable names\nbike_share_data&lt;-bike_share_data |&gt;\n  rename(date = Date,\n         rented_count = `Rented Bike Count`,\n         hour = Hour,\n         temperature = `Temperature(°C)`,\n         humidity = `Humidity(%)`,\n         wind_speed = `Wind speed (m/s)`,\n         visibility = `Visibility (10m)`,\n         dew_point = `Dew point temperature(°C)`,\n         radiation = `Solar Radiation (MJ/m2)`,\n         rainfall = `Rainfall(mm)`,\n         snowfall = `Snowfall (cm)`,\n         season = Seasons,\n         holiday = Holiday,\n         functional = `Functioning Day`)\n\n\n\nSummarizing the Hourly Data\nWe’ve already produced overall summary statistics for our numeric variables. In doing so, we saw that there were roughly 705 bikes rented each hour, on average. We also saw that there was a substantial amount of variation with the standard deviation being nearly as large as the mean (645 bikes).\nNow, let’s generate the same summary statistics for our variable of interest (number of bikes rented) by levels of season, holiday, and functional.\nTo start, we will summarize rental counts across levels of the functioning indicator, as it may reflect the hours the program is and is not operational.\n\n#Generating summary statistics for bikes rented by functional\nbike_share_data |&gt;\n  group_by(functional) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 2 × 8\n  functional variable      mean median    sd   IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 No         rented_count    0       0    0      0     0     0\n2 Yes        rented_count  729.    542  642.   870     2  3556\n\n\nIndeed, there are no rentals for the hours in which functional is “no”. Let’s subset to only observations where this indicator has a value of “yes”.\n\n#Subsetting to only operating hours\nbike_share_data&lt;-bike_share_data |&gt;\n  filter(functional==\"Yes\") |&gt;\n  select(!functional)\n\n\n#Generating summary statistics for bikes rented by season\nbike_share_data |&gt;\n  group_by(season) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 4 × 8\n  season variable      mean median    sd   IQR   min   max\n  &lt;fct&gt;  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn rented_count  924.   856   618.  844      2  3298\n2 Spring rented_count  746.   599   619.  893      2  3251\n3 Summer rented_count 1034.   906.  690.  916.     9  3556\n4 Winter rented_count  226.   203   150.  195      3   937\n\n\nNote that winter has much lower average hourly rentals. This makes sense as this is the coldest time of the year.\nNow, let’s look at rental rates by the holiday indicator.\n\n#Generating summary statistics for bikes rented by holiday indicator\nbike_share_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 2 × 8\n  holiday    variable      mean median    sd   IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holiday    rented_count  529.    259  574.  694.     3  2400\n2 No Holiday rented_count  739.    561  644.  872      2  3556\n\n\nInterestingly, the average hourly rental count is lower on holidays. This may be because holidays are more likely to occur in colder seasons, or it may be because the bikes are commonly used to travel to and from work.\nTo investigate this, let’s look at rental counts by season AND holiday.\n\n#Generating summary statistics for bikes rented by season and holiday indicator\n\nbike_share_data |&gt;\n  group_by(season, holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n`summarise()` has grouped output by 'season'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 9\n# Groups:   season [4]\n  season holiday    variable      mean median    sd   IQR   min   max\n  &lt;fct&gt;  &lt;fct&gt;      &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn Holiday    rented_count  948.   900   603.  973.   105  2400\n2 Autumn No Holiday rented_count  923.   852   618.  833      2  3298\n3 Spring Holiday    rented_count  635.   366.  609.  870.    11  2082\n4 Spring No Holiday rented_count  750.   605   619.  890.     2  3251\n5 Summer Holiday    rented_count 1022.   925   564.  848.   218  2163\n6 Summer No Holiday rented_count 1034.   904.  693.  918      9  3556\n7 Winter Holiday    rented_count  157.   138   108.  150      3   671\n8 Winter No Holiday rented_count  232.   212   152.  196.     7   937\n\n\nIt seems the average hourly rental count is lower on holidays in spring and winter. However, the opposite is true in the fall and the difference is negligible in the summer.\nAs a final step, let’s look at pairwise correlations for the numeric variables.\n\nbike_share_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  kable(caption=\"Pairwise Correlations for Numeric Variables (Hourly)\") |&gt;\n  kable_styling() |&gt;\n  column_spec(column = 1,bold = TRUE) \n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPairwise Correlations for Numeric Variables (Hourly)\n\n\n\nrented_count\ntemperature\nhumidity\nwind_speed\nvisibility\ndew_point\nradiation\nrainfall\nsnowfall\n\n\n\n\nrented_count\n1.0000000\n0.5627402\n-0.2019727\n0.1250219\n0.2123228\n0.4002628\n0.2738616\n-0.1286261\n-0.1516108\n\n\ntemperature\n0.5627402\n1.0000000\n0.1664252\n-0.0384808\n0.0282621\n0.9144670\n0.3548435\n0.0521489\n-0.2177458\n\n\nhumidity\n-0.2019727\n0.1664252\n1.0000000\n-0.3373524\n-0.5485418\n0.5394024\n-0.4572727\n0.2369169\n0.1101265\n\n\nwind_speed\n0.1250219\n-0.0384808\n-0.3373524\n1.0000000\n0.1804276\n-0.1771701\n0.3262219\n-0.0249313\n-0.0037893\n\n\nvisibility\n0.2123228\n0.0282621\n-0.5485418\n0.1804276\n1.0000000\n-0.1825864\n0.1530461\n-0.1703518\n-0.1228597\n\n\ndew_point\n0.4002628\n0.9144670\n0.5394024\n-0.1771701\n-0.1825864\n1.0000000\n0.0985250\n0.1268125\n-0.1497598\n\n\nradiation\n0.2738616\n0.3548435\n-0.4572727\n0.3262219\n0.1530461\n0.0985250\n1.0000000\n-0.0741573\n-0.0733799\n\n\nrainfall\n-0.1286261\n0.0521489\n0.2369169\n-0.0249313\n-0.1703518\n0.1268125\n-0.0741573\n1.0000000\n0.0086041\n\n\nsnowfall\n-0.1516108\n-0.2177458\n0.1101265\n-0.0037893\n-0.1228597\n-0.1497598\n-0.0733799\n0.0086041\n1.0000000\n\n\n\n\n\n\n\nFocusing on correlations with the response, it seems temperature and sunlight (proxied by radiation) have the strongest correlations with rental count. humidity has the weakest relationship with rental count, but there may still be a non-linear relationship or a linear relationship that only exists when we control for other factors correlated with humidity and rented_count.\n\n\nConverting to Daily Data\nTo simplify our analysis, let’s convert our hourly data to daily. In many ways, this is more informative, as intra-day variations add an unnecessary layer of complexity.\nTo do so, we will sum hourly rental counts, snowfall, and rainfall. We will average everything else.\n\n#Converting data to daily\nbike_share_data&lt;-bike_share_data |&gt;\n  group_by(date, season, holiday) |&gt;\n  mutate(across(c(rented_count, snowfall, rainfall),sum,.names = \"{.col}_day\"), #some variables to sums\n         across(temperature:radiation,mean,.names = \"{.col}_day\")) |&gt; #others to means\n  ungroup() |&gt;\n  distinct(date, season, holiday, .keep_all = TRUE) |&gt;\n  select(date, season, holiday, ends_with(\"_day\")) |&gt; #removing original hourly numeric variables\n  rename_with(~ str_remove(.,\"_day\"))\n\n\n\nSummarizing the Daily Data\nNow that we have daily data, let’s recreate the summary statistics we produced for the hourly data.\nTo start, let’s reproduce the overall summary statistics for our numeric variables.\n\n#Generating basic summary statistics for the numeric variables\nbike_share_data |&gt;\n  summarize(across(where(is.numeric),list(\"mean\" = mean,\n                                     \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(everything(),names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 9 × 7\n  variable          mean    median       sd       IQR      min      max\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 rented_count 17485.    18563     9937.    19318     977      36149   \n2 snowfall         1.86      0        8.80      0       0         78.7 \n3 rainfall         3.58      0       11.8       0.5     0         95.5 \n4 temperature     12.8      13.7     11.7      19.3   -14.7       33.7 \n5 humidity        58.2      57.2     14.9      20.1    22.2       95.9 \n6 wind_speed       1.73      1.66     0.597     0.65    0.662      4   \n7 visibility    1434.     1558.     491.      787.    214.      2000   \n8 dew_point        3.95      4.61    13.0      20.1   -27.8       25.0 \n9 radiation        0.568     0.565    0.316     0.537   0.0292     1.22\n\n\nThis clearly demonstrates our transformations, as the previously hourly averages for rented_count, snowfall, and rainfall have now been effectively scaled up to reflect the 24-hour period.\nNow to the arguably more interesting tables, let’s look at the bike rental counts by season.\n\n#Generating summary statistics for bikes rented by season\nbike_share_data |&gt;\n  group_by(season) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 4 × 8\n  season variable       mean median    sd    IQR   min   max\n  &lt;fct&gt;  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn rented_count 22099. 23350  6711. 10733   1721 31809\n2 Spring rented_count 17910. 17590  8357. 14362.   977 31681\n3 Summer rented_count 24818. 25572. 7297.  9308.  3231 36149\n4 Winter rented_count  5413.  5498  1808.  2634.  2014  9539\n\n\nWe see the same pattern as we did for the hourly data, with summer and autumn having the highest daily average counts. One interesting note we did not discuss previously: the standard deviation, inner quartile range, and range all indicate that spring sees the greatest volatility in bike share activity across days. This is not particularly surprising as spring likely has both cold, snowy days and warm, sunny days.\nLet’s look again at rental activity by the holiday indicator.\n\n#Generating summary statistics for bikes rented by holiday indicator\nbike_share_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 2 × 8\n  holiday    variable       mean median     sd    IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holiday    rented_count 12700.  7184  10504. 16576   2014 30498\n2 No Holiday rented_count 17727. 19104.  9862. 19168.   977 36149\n\n\nWe again see the intriguing factor that non-holiday days in our sample see greater rental activity, on average.\nAs we did previously, we will explore whether this relationship holds across seasons.\n\n#Generating summary statistics for bikes rented by season and holiday indicator\n\nbike_share_data |&gt;\n  group_by(season, holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n`summarise()` has grouped output by 'season'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 9\n# Groups:   season [4]\n  season holiday    variable       mean median     sd    IQR   min   max\n  &lt;fct&gt;  &lt;fct&gt;      &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn Holiday    rented_count 22754. 21705   5642.  5740  17259 30349\n2 Autumn No Holiday rented_count 22065. 23472   6792. 10734   1721 31809\n3 Spring Holiday    rented_count 15247. 13790  10917. 10844   5132 26820\n4 Spring No Holiday rented_count 18002. 17730   8322. 14224.   977 31681\n5 Summer Holiday    rented_count 24532. 24532.  8438.  5966. 18565 30498\n6 Summer No Holiday rented_count 24824. 25572.  7324.  9165   3231 36149\n7 Winter Holiday    rented_count  3759   3454.  1561.  1060.  2014  7184\n8 Winter No Holiday rented_count  5574.  5609   1757.  2564   2487  9539\n\n\nWe again see that non-holiday days see more activity, on average, than holiday days only in spring and winter.\nBefore we produce graphical summaries of the data, let’s reproduce the pairwise correlation table.\n\nbike_share_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  kable(caption=\"Pairwise Correlations for Numeric Variables (Daily)\") |&gt;\n  kable_styling() |&gt;\n  column_spec(column = 1,bold = TRUE) \n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPairwise Correlations for Numeric Variables (Daily)\n\n\n\nrented_count\nsnowfall\nrainfall\ntemperature\nhumidity\nwind_speed\nvisibility\ndew_point\nradiation\n\n\n\n\nrented_count\n1.0000000\n-0.2652911\n-0.2391091\n0.7530767\n0.0358870\n-0.1928814\n0.1659937\n0.6504765\n0.7358929\n\n\nsnowfall\n-0.2652911\n1.0000000\n-0.0231340\n-0.2669637\n0.0653919\n0.0208816\n-0.1018890\n-0.2095529\n-0.2334306\n\n\nrainfall\n-0.2391091\n-0.0231340\n1.0000000\n0.1445173\n0.5286426\n-0.1016758\n-0.2219939\n0.2645662\n-0.3227041\n\n\ntemperature\n0.7530767\n-0.2669637\n0.1445173\n1.0000000\n0.4041675\n-0.2607218\n0.0023367\n0.9627963\n0.5502743\n\n\nhumidity\n0.0358870\n0.0653919\n0.5286426\n0.4041675\n1.0000000\n-0.2342578\n-0.5591773\n0.6320473\n-0.2744497\n\n\nwind_speed\n-0.1928814\n0.0208816\n-0.1016758\n-0.2607218\n-0.2342578\n1.0000000\n0.2060226\n-0.2877032\n0.0961263\n\n\nvisibility\n0.1659937\n-0.1018890\n-0.2219939\n0.0023367\n-0.5591773\n0.2060226\n1.0000000\n-0.1535516\n0.2713959\n\n\ndew_point\n0.6504765\n-0.2095529\n0.2645662\n0.9627963\n0.6320473\n-0.2877032\n-0.1535516\n1.0000000\n0.3831571\n\n\nradiation\n0.7358929\n-0.2334306\n-0.3227041\n0.5502743\n-0.2744497\n0.0961263\n0.2713959\n0.3831571\n1.0000000\n\n\n\n\n\n\n\nThere are no major differences between the daily and hourly correlations.\nLet’s now look at scatterplots that visually compare our response to each numeric predictor.\n\nplot_list&lt;-list()\n\nfor (v in names(bike_share_data)[5:12]) {\n  g&lt;-ggplot(data=bike_share_data,aes(x = !!sym(v),y = rented_count)) + geom_point() + \n    labs(y = \"Rented Bikes\")\n  plot_list&lt;-c(plot_list,g) \n}\n\nwrap_plots(plot_list) + plot_annotation(title = \"Daily Bike Rentals vs. Each Numeric Predictor\")\n\n\n\n\n\n\n\n\nOne thing stands out that was reflected in the overall summary statistics table: the majority of days have no rain and/or no snow.\nOverall, there are no clear signs of any non-linear relationships that would have been overlooked if we only considered correlations.\nIf we were focused on inference, the fanning of rented bikes counts as dew point and temperature increased would be of concern because of the constant variance assumption for linear regression models. Fortunately, we are focused on prediction.\n\n\n\nSplitting the Data\nTo evaluate the predictive capabilities of the multiple linear regression models we build, we need to split the data into training and test sets. Let’s retain 75% of the data for training and stratify by season to ensure the seasonal breakdowns are similar across training and test sets.\n\n#Setting seed for reproducibility\nset.seed(10)\n\n#Splitting the data into training and test sets \nbike_share_split&lt;-initial_split(bike_share_data, strata = season, prop = 0.75)\n\n#Printing the structure of the split object\nbike_share_split\n\n&lt;Training/Testing/Total&gt;\n&lt;263/90/353&gt;\n\n\nNote that in printing the structure we see that 263 of the 353 day-level observations are retained in the training set; the other 90 observations are places in the test set.\nLet’s extract the training and test sets for use in our analysis. Let’s also split the training set into 10 folds so that we can identify the best model among candidate linear regression models using 10-fold cross validation.\n\n#Setting seed for reproducibility \nset.seed(5)\n\n#Extracting training and test sets\nbike_share_train&lt;-training(bike_share_split)\nbike_share_test&lt;-testing(bike_share_split)\n\n#Separating the training data into the 10 folds\nfolds&lt;-vfold_cv(bike_share_train, v = 10)\n\n#Printing the structure of the folds object\nfolds\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits           id    \n   &lt;list&gt;           &lt;chr&gt; \n 1 &lt;split [236/27]&gt; Fold01\n 2 &lt;split [236/27]&gt; Fold02\n 3 &lt;split [236/27]&gt; Fold03\n 4 &lt;split [237/26]&gt; Fold04\n 5 &lt;split [237/26]&gt; Fold05\n 6 &lt;split [237/26]&gt; Fold06\n 7 &lt;split [237/26]&gt; Fold07\n 8 &lt;split [237/26]&gt; Fold08\n 9 &lt;split [237/26]&gt; Fold09\n10 &lt;split [237/26]&gt; Fold10\n\n\nIn printing folds, we see that we have segmented the training data into 10 folds.\n\n\nModeling Rental Counts with Multiple Linear Regression Models\nNow we can build some models. The first model we will specify has the following characteristics:\n\nAll variables in the dataset are used to predict rented_count\n\nThe one caveat is that we use a weekend indicator rather than date explicitly\n\nAll numeric variables are normalized\nDummies are creates for the levels of the factor variables (season, holiday, and the new weekend indicator)\n\n\n#Constructing first recipe\nbike_rec_1&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features=c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend)\n\n#Printing recipe variable list with roles\nbike_rec_1 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary()\n\n# A tibble: 15 × 4\n   variable           type      role      source  \n   &lt;chr&gt;              &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date               &lt;chr [1]&gt; ID        original\n 2 snowfall           &lt;chr [2]&gt; predictor original\n 3 rainfall           &lt;chr [2]&gt; predictor original\n 4 temperature        &lt;chr [2]&gt; predictor original\n 5 humidity           &lt;chr [2]&gt; predictor original\n 6 wind_speed         &lt;chr [2]&gt; predictor original\n 7 visibility         &lt;chr [2]&gt; predictor original\n 8 dew_point          &lt;chr [2]&gt; predictor original\n 9 radiation          &lt;chr [2]&gt; predictor original\n10 rented_count       &lt;chr [2]&gt; outcome   original\n11 season_Spring      &lt;chr [2]&gt; predictor derived \n12 season_Summer      &lt;chr [2]&gt; predictor derived \n13 season_Winter      &lt;chr [2]&gt; predictor derived \n14 holiday_No.Holiday &lt;chr [2]&gt; predictor derived \n15 weekend_yes        &lt;chr [2]&gt; predictor derived \n\n\nIn printing the summary of the prepped recipe, we can see that date now has the role “ID” rather than “predictor”. We can also see the indicators that were created.\nLet’s specify a second model that includes all the previous characteristics, but also includes interactions for season and holiday, season and temperature, and temperature and rainfall.\n\n#Constructing first recipe\nbike_rec_2&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features=c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend) |&gt;\n  #Adding season-holiday interaction\n  step_interact(terms = ~holiday_No.Holiday*starts_with(\"season\")) |&gt;\n  #Adding season-temp interaction \n  step_interact(terms = ~temperature*starts_with(\"season\")) |&gt;\n  #Adding temperature-rainfall interaction \n  step_interact(terms = ~temperature*rainfall)\n  \n\n#Printing recipe variable list with roles\nbike_rec_2 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary()\n\n# A tibble: 22 × 4\n   variable     type      role      source  \n   &lt;chr&gt;        &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date         &lt;chr [1]&gt; ID        original\n 2 snowfall     &lt;chr [2]&gt; predictor original\n 3 rainfall     &lt;chr [2]&gt; predictor original\n 4 temperature  &lt;chr [2]&gt; predictor original\n 5 humidity     &lt;chr [2]&gt; predictor original\n 6 wind_speed   &lt;chr [2]&gt; predictor original\n 7 visibility   &lt;chr [2]&gt; predictor original\n 8 dew_point    &lt;chr [2]&gt; predictor original\n 9 radiation    &lt;chr [2]&gt; predictor original\n10 rented_count &lt;chr [2]&gt; outcome   original\n# ℹ 12 more rows\n\n\nWhen printing the summary of this prepped recipe, we see the interaction terms; the “x” in the interaction term names is a nice touch by the tidyverse.\nLet’s specify a final model, which includes all of the characteristics as the second model and also includes quadratic terms for the numeric predictors.\n\n#Constructing first recipe\nbike_rec_3&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features=c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Adding quadratic terms for numeric variables\n  step_poly(all_numeric(), -all_outcomes(), degree = 2, options = list(raw = TRUE)) |&gt; \n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend) |&gt;\n  #Adding season-holiday interaction\n  step_interact(terms = ~holiday_No.Holiday*starts_with(\"season\")) |&gt;\n  #Adding season-temp interaction \n  step_interact(terms = ~temperature_poly_1*starts_with(\"season\")) |&gt;\n  #Adding temperature-rainfall interaction \n  step_interact(terms = ~temperature_poly_1*rainfall_poly_1)\n  \n\n#Printing recipe variable list with roles\nbike_rec_3 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary()\n\n# A tibble: 30 × 4\n   variable           type      role      source  \n   &lt;chr&gt;              &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date               &lt;chr [1]&gt; ID        original\n 2 rented_count       &lt;chr [2]&gt; outcome   original\n 3 snowfall_poly_1    &lt;chr [2]&gt; predictor derived \n 4 snowfall_poly_2    &lt;chr [2]&gt; predictor derived \n 5 rainfall_poly_1    &lt;chr [2]&gt; predictor derived \n 6 rainfall_poly_2    &lt;chr [2]&gt; predictor derived \n 7 temperature_poly_1 &lt;chr [2]&gt; predictor derived \n 8 temperature_poly_2 &lt;chr [2]&gt; predictor derived \n 9 humidity_poly_1    &lt;chr [2]&gt; predictor derived \n10 humidity_poly_2    &lt;chr [2]&gt; predictor derived \n# ℹ 20 more rows\n\n\nWe now have quadratic terms; note that the original numeric variables now have a “_poly_1” suffix to explicitly indicate they are still linear terms.\nOur next step is to specify the type of model we want to fit, which is the linear regression model.\n\n#Specifying an ordinary least squares model\nlm_model&lt;-linear_reg() |&gt;\n  set_engine(\"lm\")\n\nIt is finally time to fit some models and see how well they predict! The code below fits each of the three models we have specified above for each of the 10 “training” sets and collects their cross-validated prediction error metrics.\n\n#Fitting first model to each \"training\" set and testing for each fold \nbike_fit_1&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Fitting second model to each \"training\" set and testing for each fold \nbike_fit_2&lt;-workflow() |&gt;\n  add_recipe(bike_rec_2) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Fitting third model to each \"training\" set and testing for each fold \nbike_fit_3&lt;-workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Capturing fit metrics\nrbind(bike_fit_1 |&gt; collect_metrics() |&gt; mutate(model = 1) |&gt; select(model, everything()),\n      bike_fit_2 |&gt; collect_metrics() |&gt; mutate(model = 2) |&gt; select(model, everything()),\n      bike_fit_3 |&gt; collect_metrics() |&gt; mutate(model = 3) |&gt; select(model, everything()))\n\n# A tibble: 6 × 7\n  model .metric .estimator     mean     n  std_err .config        \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1     1 rmse    standard   4333.       10  85.4    pre0_mod0_post0\n2     1 rsq     standard      0.818    10   0.0113 pre0_mod0_post0\n3     2 rmse    standard   3123.       10 265.     pre0_mod0_post0\n4     2 rsq     standard      0.902    10   0.0177 pre0_mod0_post0\n5     3 rmse    standard   3069.       10 280.     pre0_mod0_post0\n6     3 rsq     standard      0.904    10   0.0185 pre0_mod0_post0\n\n\nBased on the cross-validated “test” root mean squared error (RMSE), the third linear regression model predicts the number of rented bikes best.\nNow that we’ve identified the best model, let’s fit the model to the entire training set and obtain a final estimate of the out-of-sample RMSE using the original test set.\n\n#Fitting model to full training set and testing on full test set\nfinal_fit&lt;-workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(lm_model) |&gt;\n  last_fit(bike_share_split)\n\n#Extracting predictive performance for test set\nfinal_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    2963.    pre0_mod0_post0\n2 rsq     standard       0.918 pre0_mod0_post0\n\n\nAs we would expect, the test RMSE is similar to that of the cross-validated RMSE we previously obtained for this model. In fact, the RMSE is slightly lower here, which could be explained by the fact that we used the full training set to train this model or simply by randomness.\nAs a final step, let’s extract a summary of the model fit.\n\n#Extracting fit summary\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy() |&gt;\n  kable()\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n18209.37765\n1508.76688\n12.0690465\n0.0000000\n\n\nsnowfall_poly_1\n-117.68556\n618.59272\n-0.1902472\n0.8492803\n\n\nsnowfall_poly_2\n-21.61766\n96.65746\n-0.2236522\n0.8232230\n\n\nrainfall_poly_1\n-2395.91686\n553.78090\n-4.3264708\n0.0000225\n\n\nrainfall_poly_2\n190.90294\n79.76025\n2.3934597\n0.0174793\n\n\ntemperature_poly_1\n1785.73905\n4041.27237\n0.4418755\n0.6589874\n\n\ntemperature_poly_2\n-1133.56024\n1104.11783\n-1.0266660\n0.3056379\n\n\nhumidity_poly_1\n-1564.62701\n1448.20597\n-1.0803898\n0.2810809\n\n\nhumidity_poly_2\n-292.73851\n300.46992\n-0.9742689\n0.3309291\n\n\nwind_speed_poly_1\n-621.07193\n259.94867\n-2.3892099\n0.0176778\n\n\nwind_speed_poly_2\n165.06296\n127.65542\n1.2930353\n0.1972740\n\n\nvisibility_poly_1\n334.28976\n303.56435\n1.1012155\n0.2719343\n\n\nvisibility_poly_2\n-120.67233\n214.16845\n-0.5634458\n0.5736709\n\n\ndew_point_poly_1\n4261.53746\n4648.35411\n0.9167842\n0.3601996\n\n\ndew_point_poly_2\n-313.49257\n729.94508\n-0.4294742\n0.6679733\n\n\nradiation_poly_1\n2837.25189\n382.74822\n7.4128416\n0.0000000\n\n\nradiation_poly_2\n-629.22217\n234.85741\n-2.6791668\n0.0079045\n\n\nseason_Spring\n-2633.38731\n2599.25387\n-1.0131320\n0.3120435\n\n\nseason_Summer\n18967.91348\n3170.71942\n5.9822113\n0.0000000\n\n\nseason_Winter\n-7288.67111\n2815.88995\n-2.5884077\n0.0102457\n\n\nholiday_No.Holiday\n5549.79451\n1497.30154\n3.7065310\n0.0002623\n\n\nweekend_yes\n-2492.73551\n397.78252\n-6.2665789\n0.0000000\n\n\nholiday_No.Holiday_x_season_Spring\n-1366.74899\n2662.05569\n-0.5134186\n0.6081429\n\n\nholiday_No.Holiday_x_season_Summer\n-1661.95577\n2502.46204\n-0.6641283\n0.5072621\n\n\nholiday_No.Holiday_x_season_Winter\n-3848.82785\n1900.37832\n-2.0252956\n0.0439724\n\n\ntemperature_poly_1_x_season_Spring\n5895.06124\n1075.17730\n5.4828736\n0.0000001\n\n\ntemperature_poly_1_x_season_Summer\n-16875.80766\n2431.62763\n-6.9401283\n0.0000000\n\n\ntemperature_poly_1_x_season_Winter\n-5216.36619\n2903.64863\n-1.7964867\n0.0737069\n\n\ntemperature_poly_1_x_rainfall_poly_1\n-1679.91534\n445.97450\n-3.7668417\n0.0002092\n\n\n\n\n\nAs we have not fully evaluated all of the assumptions underlying the p-values, we must be cautious in drawing any inferential conclusions for any of the coefficients. Additionally, the complex non-linear relationships modeled here make interpretation difficult. Acknowledging these limitations, there are still interesting relationships revealed by the coefficients and their p-values. For example, the effect of increasing temperature varies substantially by season, as we see that an increase in temperatures has a uniquely large negative impact on rental activity in the summer. This makes sense, as the average temperature in summer will already be warm and increases of a few degrees Celsius (or a few standard deviations in the model) could correspond to an uncomfortably hot day.\nAdditionally, higher levels of radiation (more sunny day) generally correspond to more rental activity, but there are diminishing returns to increased radiation reflected in the negative quadratic term."
  }
]